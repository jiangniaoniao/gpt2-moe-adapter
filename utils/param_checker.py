import torch
import torch.nn as nn

def check_parameter_freezing(model):
    """è¯¦ç»†æ£€æŸ¥å‚æ•°å†»ç»“çŠ¶æ€"""
    print("ğŸ” å‚æ•°å†»ç»“çŠ¶æ€æ£€æŸ¥:")
    
    total_params = 0
    frozen_params = 0
    trainable_params = 0
    
    # æ£€æŸ¥åŸºç¡€GPT-2å‚æ•°
    gpt2_params = 0
    frozen_gpt2_params = 0
    
    for name, param in model.gpt2.named_parameters():
        gpt2_params += param.numel()
        if not param.requires_grad:
            frozen_gpt2_params += param.numel()
    
    # æ£€æŸ¥é€‚é…å™¨å‚æ•°
    adapter_params = 0
    trainable_adapter_params = 0
    
    for name, param in model.named_parameters():
        total_params += param.numel()
        if param.requires_grad:
            trainable_params += param.numel()
        else:
            frozen_params += param.numel()
        
        if 'smear_adapters' in name or 'adapter_alpha' in name:
            adapter_params += param.numel()
            if param.requires_grad:
                trainable_adapter_params += param.numel()
    
    print(f"ğŸ“Š å‚æ•°ç»Ÿè®¡:")
    print(f"  æ€»å‚æ•°: {total_params:,}")
    print(f"  å¯è®­ç»ƒå‚æ•°: {trainable_params:,} ({trainable_params/total_params*100:.2f}%)")
    print(f"  å†»ç»“å‚æ•°: {frozen_params:,} ({frozen_params/total_params*100:.2f}%)")
    print(f"  GPT-2å‚æ•°: {gpt2_params:,} (å†»ç»“: {frozen_gpt2_params:,})")
    print(f"  é€‚é…å™¨å‚æ•°: {adapter_params:,} (å¯è®­ç»ƒ: {trainable_adapter_params:,})")
    
    # éªŒè¯å…³é”®æ¡ä»¶
    conditions_met = []
    
    # æ¡ä»¶1: GPT-2å‚æ•°åº”è¯¥å®Œå…¨å†»ç»“
    if frozen_gpt2_params == gpt2_params:
        conditions_met.append("âœ… GPT-2å‚æ•°å®Œå…¨å†»ç»“")
    else:
        conditions_met.append("âŒ GPT-2å‚æ•°æœªå®Œå…¨å†»ç»“")
    
    # æ¡ä»¶2: é€‚é…å™¨å‚æ•°åº”è¯¥å¯è®­ç»ƒ
    if trainable_adapter_params == adapter_params:
        conditions_met.append("âœ… é€‚é…å™¨å‚æ•°å®Œå…¨å¯è®­ç»ƒ")
    else:
        conditions_met.append("âŒ é€‚é…å™¨å‚æ•°æœªå®Œå…¨å¯è®­ç»ƒ")
    
    # æ¡ä»¶3: å¯è®­ç»ƒå‚æ•°æ¯”ä¾‹åº”è¯¥å¾ˆå°
    trainable_ratio = trainable_params / total_params
    if trainable_ratio < 0.1:  # å°‘äº10%
        conditions_met.append(f"âœ… å‚æ•°æ•ˆç‡è‰¯å¥½ ({trainable_ratio*100:.2f}% å¯è®­ç»ƒ)")
    else:
        conditions_met.append(f"âš ï¸ å‚æ•°æ•ˆç‡å¯èƒ½ä¸è¶³ ({trainable_ratio*100:.2f}% å¯è®­ç»ƒ)")
    
    print("ğŸ“‹ æ¡ä»¶éªŒè¯:")
    for condition in conditions_met:
        print(f"  {condition}")
    
    return all("âœ…" in condition for condition in conditions_met)

def verify_smear_architecture(model):
    """éªŒè¯SMEARæ¶æ„å®Œæ•´æ€§"""
    print("\nğŸ” SMEARæ¶æ„éªŒè¯:")
    
    # æ£€æŸ¥æ˜¯å¦å­˜åœ¨æ—è·¯è¿æ¥
    has_bypass = hasattr(model, 'adapter_alpha')
    print(f"  æ—è·¯ç¼©æ”¾ç³»æ•°: {'âœ…' if has_bypass else 'âŒ'}")
    
    # æ£€æŸ¥é€‚é…å™¨å±‚æ•°
    if hasattr(model, 'smear_adapters'):
        adapter_count = len(model.smear_adapters)
        expected_count = len(model.config.adapter_layers)
        print(f"  é€‚é…å™¨å±‚æ•°: {adapter_count}/{expected_count} {'âœ…' if adapter_count == expected_count else 'âŒ'}")
    
    # æ£€æŸ¥å‚æ•°è½¯åˆå¹¶
    print(f"  å‚æ•°è½¯åˆå¹¶: âœ… (SMEARæ ¸å¿ƒç‰¹æ€§)")
    
    # æ£€æŸ¥è·¯ç”±æœºåˆ¶
    if hasattr(model, 'smear_adapters') and len(model.smear_adapters) > 0:
        first_adapter = model.smear_adapters[0]
        has_router = hasattr(first_adapter, 'router')
        has_expert = hasattr(first_adapter, 'expert')
        print(f"  è·¯ç”±å™¨æœºåˆ¶: {'âœ…' if has_router else 'âŒ'}")
        print(f"  ä¸“å®¶æ± : {'âœ…' if has_expert else 'âŒ'}")