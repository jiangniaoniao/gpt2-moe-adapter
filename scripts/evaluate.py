import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(__file__)))

import torch
from transformers import GPT2Tokenizer

from config.base_config import GPT2MoEConfig, MoEAdapterConfig
from models.gpt2_moe_model import GPT2WithMoEAdapter
from training.data_loader import get_wikitext_dataloaders

def evaluate_model():
    """è¯„ä¼°è®­ç»ƒå¥½çš„æ¨¡å‹"""
    
    # åŠ è½½é…ç½®
    adapter_config = MoEAdapterConfig(
        num_experts=8,
        expert_size=512,
        router_type="soft"
    )
    
    model_config = GPT2MoEConfig(
        base_model="gpt2",
        num_adapter_layers=6,
        adapter_layers=[2, 4, 6, 8, 10, 12],
        freeze_base_model=True,
        adapter_config=adapter_config
    )
    
    # åˆ›å»ºæ¨¡å‹
    model = GPT2WithMoEAdapter(model_config)
    
    # åŠ è½½è®­ç»ƒå¥½çš„é€‚é…å™¨æƒé‡
    adapter_weights = torch.load("./output/best_model_epoch_0/adapter_weights.pth")
    model.load_state_dict(adapter_weights, strict=False)
    
    # ç§»åŠ¨åˆ°è®¾å¤‡
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model.to(device)
    model.eval()
    
    # è·å–æ•°æ®åŠ è½½å™¨
    training_config = type('Config', (), {
        'dataset_name': 'wikitext',
        'dataset_config': 'wikitext-2-raw-v1',
        'max_length': 1024,
        'batch_size': 4
    })()
    
    _, val_loader, _ = get_wikitext_dataloaders(training_config)
    
    # è¯„ä¼°
    total_loss = 0
    total_perplexity = 0
    
    with torch.no_grad():
        for batch in val_loader:
            input_ids = batch['input_ids'].to(device)
            attention_mask = batch['attention_mask'].to(device)
            labels = batch['labels'].to(device)
            
            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)
            loss = outputs['loss']
            
            total_loss += loss.item()
            perplexity = torch.exp(torch.tensor(loss.item()))
            total_perplexity += perplexity.item()
    
    avg_loss = total_loss / len(val_loader)
    avg_perplexity = total_perplexity / len(val_loader)
    
    print(f"ğŸ“Š è¯„ä¼°ç»“æœ:")
    print(f"  - å¹³å‡æŸå¤±: {avg_loss:.4f}")
    print(f"  - å¹³å‡å›°æƒ‘åº¦: {avg_perplexity:.4f}")

if __name__ == "__main__":
    evaluate_model()