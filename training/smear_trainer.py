import torch
import torch.nn as nn
from torch.optim import AdamW
from transformers import get_linear_schedule_with_warmup
from tqdm import tqdm
import os
import json

class SmearTrainer:
    """ä¸“é—¨ä¸ºSMEARæ–¹æ³•è®¾è®¡çš„è®­ç»ƒå™¨"""
    
    def __init__(self, model, train_loader, val_loader, config):
        self.model = model
        self.train_loader = train_loader
        self.val_loader = val_loader
        self.config = config
        
        # ä¼˜åŒ–å™¨ - åªè®­ç»ƒAdapterå‚æ•°
        trainable_params = [p for p in model.parameters() if p.requires_grad]
        self.optimizer = AdamW(trainable_params, lr=config.learning_rate, weight_decay=config.weight_decay)
        
        # å­¦ä¹ ç‡è°ƒåº¦å™¨
        self.scheduler = get_linear_schedule_with_warmup(
            self.optimizer,
            num_warmup_steps=config.warmup_steps,
            num_training_steps=config.total_steps
        )
        
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.model.to(self.device)
        
        # è®­ç»ƒç»Ÿè®¡
        self.train_stats = {
            'losses': [],
            'lm_losses': [],
            'perplexities': [],
            'routing_diversity': []  # SMEARç‰¹æœ‰çš„è·¯ç”±å¤šæ ·æ€§ç»Ÿè®¡
        }
        
        print(f"ğŸš€ åˆå§‹åŒ–SMEARè®­ç»ƒå™¨")
        print(f"   - è®¾å¤‡: {self.device}")
        print(f"   - å¯è®­ç»ƒå‚æ•°: {sum(p.numel() for p in trainable_params):,}")
    
    def train_epoch(self, epoch):
        """è®­ç»ƒä¸€ä¸ªepoch - SMEARä¸“ç”¨"""
        self.model.train()
        total_loss = 0
        total_lm_loss = 0
        total_routing_diversity = 0
        
        progress_bar = tqdm(self.train_loader, desc=f'Epoch {epoch}')
        
        for batch_idx, batch in enumerate(progress_bar):
            # ç§»åŠ¨åˆ°è®¾å¤‡
            input_ids = batch['input_ids'].to(self.device)
            attention_mask = batch['attention_mask'].to(self.device)
            labels = batch['labels'].to(self.device)
            
            # å‰å‘ä¼ æ’­
            outputs = self.model(input_ids, attention_mask=attention_mask, labels=labels)
            loss = outputs['loss']
            
            # åå‘ä¼ æ’­
            self.optimizer.zero_grad()
            loss.backward()
            
            # æ¢¯åº¦è£å‰ª
            torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.config.max_grad_norm)
            
            self.optimizer.step()
            self.scheduler.step()
            
            # ç»Ÿè®¡ - SMEARä¸“ç”¨
            total_loss += loss.item()
            
            lm_loss = outputs.get('lm_loss', None)
            if lm_loss is not None:
                total_lm_loss += lm_loss.item()
            
            # è®¡ç®—è·¯ç”±å¤šæ ·æ€§ï¼ˆSMEARç‰¹æœ‰ï¼‰
            routing_diversity = self._compute_routing_diversity(outputs.get('routing_info', []))
            total_routing_diversity += routing_diversity
            
            # æ›´æ–°è¿›åº¦æ¡
            progress_bar.set_postfix({
                'Loss': f'{loss.item():.4f}',
                'LM Loss': f'{lm_loss.item() if lm_loss is not None else 0:.4f}',
                'Routing Diversity': f'{routing_diversity:.4f}'
            })
            
            # è®°å½•è·¯ç”±ä¿¡æ¯
            routing_info = outputs.get('routing_info', [])
            if batch_idx % 100 == 0 and routing_info:
                self._log_smear_routing_info(routing_info, epoch, batch_idx)
        
        # è®°å½•epochç»Ÿè®¡
        avg_loss = total_loss / len(self.train_loader)
        avg_lm_loss = total_lm_loss / len(self.train_loader) if total_lm_loss > 0 else 0
        avg_routing_diversity = total_routing_diversity / len(self.train_loader)
        
        self.train_stats['losses'].append(avg_loss)
        self.train_stats['lm_losses'].append(avg_lm_loss)
        self.train_stats['routing_diversity'].append(avg_routing_diversity)
        
        return avg_loss, avg_lm_loss, avg_routing_diversity
    
    def _compute_routing_diversity(self, routing_info):
        """è®¡ç®—SMEARè·¯ç”±å¤šæ ·æ€§ï¼ˆä¸“å®¶æƒé‡åˆ†å¸ƒçš„ç†µï¼‰"""
        if not routing_info:
            return 0.0
        
        total_diversity = 0.0
        count = 0
        
        for info in routing_info:
            if 'routing_weights' in info:
                routing_weights = info['routing_weights']  # [batch_size, num_experts]
                
                # è®¡ç®—å¹³å‡è·¯ç”±æƒé‡
                avg_weights = torch.mean(routing_weights, dim=0)
                
                # è®¡ç®—ç†µä½œä¸ºå¤šæ ·æ€§æŒ‡æ ‡
                entropy = -torch.sum(avg_weights * torch.log(avg_weights + 1e-8))
                total_diversity += entropy.item()
                count += 1
        
        return total_diversity / count if count > 0 else 0.0
    
    def _log_smear_routing_info(self, routing_info, epoch, batch_idx):
        """è®°å½•SMEARè·¯ç”±ä¿¡æ¯"""
        print(f"\nğŸ“Š Epoch {epoch}, Batch {batch_idx} - SMEARè·¯ç”±ä¿¡æ¯:")
        
        for info in routing_info:
            layer = info.get('layer', 'unknown')
            
            if 'routing_weights' in info:
                routing_weights = info['routing_weights']
                avg_weights = torch.mean(routing_weights, dim=0)
                weights_str = avg_weights.cpu().detach().numpy().round(4)
                
                # è®¡ç®—æ¯ä¸ªä¸“å®¶çš„ä½¿ç”¨å¼ºåº¦
                expert_strength = torch.mean(routing_weights, dim=0)
                dominant_expert = torch.argmax(expert_strength).item()
                
                print(f"  å±‚ {layer}:")
                print(f"    - è·¯ç”±æƒé‡: {weights_str}")
                print(f"    - ä¸»å¯¼ä¸“å®¶: {dominant_expert} (æƒé‡: {expert_strength[dominant_expert]:.4f})")
    
    def validate(self, epoch):
        """éªŒè¯ - SMEARä¸“ç”¨"""
        self.model.eval()
        total_loss = 0
        total_perplexity = 0
        
        with torch.no_grad():
            for batch in tqdm(self.val_loader, desc='Validation'):
                input_ids = batch['input_ids'].to(self.device)
                attention_mask = batch['attention_mask'].to(self.device)
                labels = batch['labels'].to(self.device)
                
                outputs = self.model(input_ids, attention_mask=attention_mask, labels=labels)
                total_loss += outputs['loss'].item()
                
                # è®¡ç®—å›°æƒ‘åº¦
                lm_loss = outputs.get('lm_loss', None)
                if lm_loss is not None:
                    perplexity = torch.exp(torch.tensor(lm_loss.item()))
                    total_perplexity += perplexity.item()
        
        avg_loss = total_loss / len(self.val_loader)
        avg_perplexity = total_perplexity / len(self.val_loader) if total_perplexity > 0 else float('inf')
        
        self.train_stats['perplexities'].append(avg_perplexity)
        
        return avg_loss, avg_perplexity
    
    def train(self):
        """å®Œæ•´è®­ç»ƒæµç¨‹"""
        best_val_loss = float('inf')
        
        print("ğŸš€ å¼€å§‹è®­ç»ƒSMEARé€‚é…å™¨æ¨¡å‹")
        
        for epoch in range(self.config.num_epochs):
            print(f"\nğŸ“ Epoch {epoch + 1}/{self.config.num_epochs}")
            
            # è®­ç»ƒ
            train_loss, train_lm_loss, train_routing_diversity = self.train_epoch(epoch)
            
            # éªŒè¯
            val_loss, val_perplexity = self.validate(epoch)
            
            print(f"ğŸ“ˆ SMEARè®­ç»ƒç»Ÿè®¡:")
            print(f"  - æ€»æŸå¤±: {train_loss:.4f}")
            print(f"  - LMæŸå¤±: {train_lm_loss:.4f}") 
            print(f"  - è·¯ç”±å¤šæ ·æ€§: {train_routing_diversity:.4f}")
            print(f"  - éªŒè¯æŸå¤±: {val_loss:.4f}")
            print(f"  - éªŒè¯å›°æƒ‘åº¦: {val_perplexity:.4f}")
            
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if val_loss < best_val_loss:
                best_val_loss = val_loss
                self.save_model(f"best_smear_model_epoch_{epoch}")
                print(f"ğŸ’¾ ä¿å­˜æœ€ä½³SMEARæ¨¡å‹ (éªŒè¯æŸå¤±: {val_loss:.4f})")
            
            # ä¿å­˜è®­ç»ƒç»Ÿè®¡
            self.save_training_stats()
    
    def save_model(self, path):
        """ä¿å­˜SMEARæ¨¡å‹"""
        os.makedirs(self.config.output_dir, exist_ok=True)
        save_path = os.path.join(self.config.output_dir, path)
        os.makedirs(save_path, exist_ok=True)
        
        # ä¿å­˜SMEARé€‚é…å™¨å‚æ•°
        model_state_dict = self.model.state_dict()
        smear_state_dict = {
            name: param for name, param in model_state_dict.items()
            if any(key in name for key in ['smear_adapters', 'adapters'])
        }
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ï¼Œä¿å­˜æ‰€æœ‰å¯è®­ç»ƒå‚æ•°
        if not smear_state_dict:
            smear_state_dict = {
                name: param for name, param in model_state_dict.items()
                if param.requires_grad
            }
        
        torch.save(smear_state_dict, os.path.join(save_path, 'smear_weights.pth'))
        
        # ä¿å­˜é…ç½®
        with open(os.path.join(save_path, 'config.json'), 'w') as f:
            json.dump(self.config.__dict__, f, indent=2)
        
        print(f"ğŸ’¾ ä¿å­˜äº† {len(smear_state_dict)} ä¸ªSMEARé€‚é…å™¨å‚æ•°")
    
    def save_training_stats(self):
        """ä¿å­˜è®­ç»ƒç»Ÿè®¡ä¿¡æ¯"""
        os.makedirs(self.config.output_dir, exist_ok=True)
        with open(os.path.join(self.config.output_dir, 'smear_training_stats.json'), 'w') as f:
            json.dump(self.train_stats, f, indent=2)